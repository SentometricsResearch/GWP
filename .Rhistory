dimnames(tbl) <- list(paste0("rep", 1:n.cores),
c("cores", "clusterApplyLB", "clusterApply", "mclapply"))
for (k in 1:n.cores) {
cat(paste0("loop cores: ", k," cores: ", cores[k], "\n"))
cl <- parallel::makeCluster(cores[k])
tbl[k,1] <- cores[k]
tmp1 <- tmp2 <- tmp3 <- vector('double', n.test)
for (i in 1:n.test) {
cat(paste0("loop test: ", i, "\n"))
tmp1[i] <- system.time({
parallel::clusterApplyLB(
cl  = cl,
x   = in.list,
fun = f.test
)
})[3]
tmp2[i] <- system.time({
parallel::clusterApply(
cl  = cl,
x   = in.list,
fun = f.test
)
})[3]
tmp3[i] <- system.time({
parallel::parLapplyLB(in.list, f.test, cl =cl)
})[3]
}
tbl[k,2] <- median(tmp1)
tbl[k,3] <- median(tmp2)
tbl[k,4] <- median(tmp3)
stopCluster(cl)
}
print(tbl)
cl <- parallel::makePSOCKcluster(cores[k])
stopCluster(cl)
cat(paste0("loop cores: ", k," cores: ", cores[k], "\n"))
cl <- parallel::makePSOCKcluster(cores[k])
tbl[k,1] <- cores[k]
tmp1 <- tmp2 <- tmp3 <- vector('double', n.test)
for (i in 1:n.test) {
cat(paste0("loop test: ", i, "\n"))
tmp1[i] <- system.time({
parallel::clusterApplyLB(
cl  = cl,
x   = in.list,
fun = f.test
)
})[3]
tmp2[i] <- system.time({
parallel::clusterApply(
cl  = cl,
x   = in.list,
fun = f.test
)
})[3]
tmp3[i] <- system.time({
parallel::parLapplyLB(in.list, f.test, cl =cl)
})[3]
}
tbl[k,2] <- median(tmp1)
tbl[k,3] <- median(tmp2)
tbl[k,4] <- median(tmp3)
stopCluster(cl)
cl <- parallel::makeForkCluster(cores[k])
cl <- snow::makeMPIcluster(cores[k])
install.packages("Rmpi")
cl <- snow::makeMPIcluster(cores[k])
cl <- snow::makeMPIcluster(cores[k])
cl <- snow::makeMPIcluster(cores[k])
cl <- snow::makeMPIcluster(cores[k])
library(Rmpi)
cl <- snow::makeMPIcluster(cores[k])
mpi.spawn.Rslaves()
cl <- snow::makeMPIcluster(cores[k])
require(textreuse)
test = textreuse::tokenize_words("the answer is blowin’ in the wind")
hashed_tokens = textreuse::hash_string(test)
hashed_tokens = textreuse::hash_string(test)
test = textreuse::tokenize_words("the answer is blowin’ in the wind")
hashed_tokens = textreuse::hash_string(test)
hashed_tokens
textreuse::hash_string("the")
min(hashed_tokens)
hashed_tokens
test[which.min(hashed_tokens)]
minhash = minhash_generator(n = 20,seed = 1234)
minhash
minhash(test)
reticulate::use_python()
reticulate::use_python()
reticulate::py_versions_windows()
reticulate::py
renv::use_python()
renv:::renv_python_envpath()
renv::ini
install.packages("pak")
rm(list = ls())
options(prompt = "R> ", continue = "+  ", width = 70,
digits = 20, max.print = 80, useFancyQuotes = FALSE)
tmp <- sessionInfo()
nam <- paste0("PART_I_R", tmp$R.version$major, ".",
tmp$R.version$minor, "_", tmp$R.version$os)
sink(file = paste0("sink_", nam, ".txt"), append = FALSE, split = TRUE) # output printed in txt
print(tmp)
######################################################
cat("\n\n")
cat("SECTION 3.1\n")
cat("-----------\n\n")
library("MSGARCH")
spec <- CreateSpec()
summary(spec)
## Example 1: A single-regime model
spec <- CreateSpec(variance.spec = list(model = "sGARCH"),
distribution.spec = list(distribution = "norm"))
## Example 2: A model with heterogeneous regimes
spec <- CreateSpec(variance.spec = list(model = c("sGARCH", "tGARCH", "eGARCH")),
distribution.spec = list(distribution = c("snorm", "sstd", "sged")))
## Example 3: A model with non-switching shape parameters
spec <- CreateSpec(variance.spec = list(model = c("sGARCH", "sGARCH")),
distribution.spec = list(distribution = c("sstd", "sstd")),
constraint.spec = list(regime.const = c("nu", "xi")))
######################################################
cat("\n\n")
cat("SECTION 3.2\n")
cat("-----------\n\n")
data("dem2gbp", package = "MSGARCH")
ms2.garch.n <- CreateSpec(variance.spec = list(model = "sGARCH"),
distribution.spec = list(distribution = "norm"),
switch.spec = list(K = 2))
fit.ml <- FitML(spec = ms2.garch.n, data = dem2gbp)
summary(fit.ml)
set.seed(1234)
fit.mcmc <- FitMCMC(spec = ms2.garch.n, data = dem2gbp)
summary(fit.mcmc)
######################################################
sigma =  matrix(c(1.260e-07,  2.000e-06, -3.803e-06,  3.449e-06,  7.752e-06, -1.025e-05, -6.374e-07,  6.402e-06,
2.000e-06,  1.616e-04, -2.103e-04,  1.574e-05,  4.960e-04, -3.999e-04, -6.601e-05,  5.605e-04,
-3.803e-06, -2.103e-04,  3.050e-04,  5.339e-05, -7.324e-04,  6.298e-04,  1.259e-04, -7.533e-04,
3.449e-06,  1.574e-05,  5.339e-05,  1.364e-02, -4.975e-03, -1.737e-03,  9.652e-04,  2.340e-03,
7.752e-06,  4.960e-04, -7.324e-04, -4.975e-03,  4.776e-02, -1.209e-02, -1.535e-03,  1.109e-02,
-1.025e-05, -3.999e-04,  6.298e-04, -1.737e-03, -1.209e-02,  7.979e-03,  7.927e-04, -6.166e-03,
-6.374e-07, -6.601e-05,  1.259e-04,  9.652e-04, -1.535e-03,  7.927e-04,  4.087e-04, -1.090e-03,
6.402e-06,  5.605e-04, -7.533e-04,  2.340e-03,  1.109e-02, -6.166e-03, -1.090e-03,  1.183e-02),
ncol = 8,nrow = 8)
set.seed(1234)
nmcmc <- 10000
nburn <- 1
nthin <- 1
library("mcmc")
f_MCMC <- function(f_posterior, data, spec, par0, ctr){
par <- mcmc::metrop(f_posterior, initial = par0, scale = sigma, nbatch = ctr$nmcmc + ctr$nburn,
data = data, spec = spec)$batch
colnames(par) = names(par0)
return(par)
}
ctr <- list(nmcmc = nmcmc, nburn = nburn,
nthin = nthin, SamplerFUN = f_MCMC)
fit.mcmc <- FitMCMC(spec = ms2.garch.n, data = dem2gbp,ctr = ctr)
summary(fit.mcmc)
par = fit.mcmc$par
save(par, file  = "mcmc.draw.with.mcmc.rda")
####################################################
cat("\n\n")
cat("SECTION 3.3\n")
cat("-----------\n\n")
pred <- predict(fit.ml, nahead = 5, do.return.draw = TRUE)
pred$vol
pred$draw[, 1:4]
######################################################
cat("\n\n")
cat("SECTION 3.4\n")
cat("-----------\n\n")
risk <- Risk(fit.ml, alpha = c(0.01, 0.05), nahead = 5)
risk$VaR
risk$ES
######################################################
cat("\n\n")
cat("SECTION 3.5\n")
cat("-----------\n\n")
simulate(fit.ml, nsim = 2, nahead = 4, nburn = 500)
BIC(fit.ml)
sr.fit <- ExtractStateFit(fit.ml)
risk1 <- Risk(sr.fit[[1]], alpha = 0.05, nahead = 5)
risk2 <- Risk(sr.fit[[2]], alpha = 0.05, nahead = 5)
VaR <- cbind(risk1$VaR, risk2$VaR)
colnames(VaR) <- c("State 1", "State 2")
VaR
sink()
#################################################################################
### EMPIRICAL ILLUSTRATIONS
### Reports the code used to generate full results in the paper
#################################################################################
rm(list = ls())
library("MSGARCH")
options(prompt = "R> ", continue = "+  ", width = 70,
digits = 20, max.print = 80, useFancyQuotes = FALSE)
tmp <- sessionInfo()
nam <- paste0("PART_II_R", tmp$R.version$major, ".",
tmp$R.version$minor, "_", tmp$R.version$os)
sink(file = paste0("sink_", nam, ".txt"), append = FALSE, split = TRUE) # output printed in txt
print(tmp)
## load SMI
data("SMI", package = "MSGARCH")
## Create MS(2)-GJR-std specification (Ardia 2008 and Ardia et al. 2008)
ms2.gjr.s <- CreateSpec(variance.spec = list(model = "gjrGARCH"),
distribution.spec = list(distribution = "std"),
switch.spec = list(K = 2),
constraint.spec = list(regime.const = "nu"))
## ML estimation
fit.ml <- FitML(ms2.gjr.s, data = SMI)
## BIC
BIC(fit.ml)
## Summary
summary(fit.ml)
## Unconditional vol
set.seed(1234)
sqrt(250) * sapply(ExtractStateFit(fit.ml), UncVol)
## Smoothed probabilities in regime 2 and volatility
smoothed.prob <- State(fit.ml)$SmoothProb[, 1, 2, drop = TRUE]
vol <- sqrt(250) * Volatility(fit.ml)
## MCMC estimation
nmcmc <- 12500
nburn <- 5000
nthin <- 5
ctr <- list(nmcmc = nmcmc, nburn = nburn,
nthin = nthin, par0 = fit.ml$par)
fit.mcmc <- FitMCMC(ms2.gjr.s, data = SMI, ctr = ctr)
summary(fit.mcmc)
## Convergence of the chain
#par(mfrow = c(3, 4))
#coda::traceplot(fit.MCMC$par)
#coda::heidel.diag(fit.MCMC$par)
#coda::acfplot(fit.MCMC$par)
## Posterior draws
draws <- as.matrix(fit.mcmc$par)
## This function computes the unconditional volatility
## for a GJR model with symmeetric disturbances
f_ucvol <- function(par) {
if (is.vector(par)) {
par <- matrix(data = par, nrow = 1, dimnames = list(1, names(par)))
}
ucvol_1 <- sqrt(250) * par[,"alpha0_1"] / (1 - (par[,"alpha1_1"] + 0.5 * par[,"alpha2_1"] + par[,"beta_1"]))
ucvol_2 <- sqrt(250) * par[,"alpha0_2"] / (1 - (par[,"alpha1_2"] + 0.5 * par[,"alpha2_2"] + par[,"beta_2"]))
out <- list(ucvol_1 = ucvol_1, ucvol_2 = ucvol_2)
return(out)
}
## Compute unconditional volatility
ucvol.draws <- f_ucvol(draws)
ucvol.bay   <- lapply(ucvol.draws, mean)
ucvol.mle   <- f_ucvol(fit.ml$par)
## Posterior mean
unlist(ucvol.bay)
## Quantiles of unconditional volatility
sapply(ucvol.draws, quantile, probs = c(0.025, 0.975))
## Impact of paramter uncertainty in pred
nmesh <- 1000
x <- seq(from = -5, to = 0, length.out = nmesh)
pred.mle <- as.vector(PredPdf(fit.ml, x = x, nahead = 1))
pred.bay <- as.vector(PredPdf(fit.mcmc, x = x, nahead = 1))
pred.draws <- matrix(data = NA, nrow = nrow(draws), ncol = nmesh)
for (i in 1:nrow(draws)) {
tmp <- PredPdf(ms2.gjr.s, par = draws[i,], x = x, data = SMI, nahead = 1)
pred.draws[i,] <- as.vector(tmp)
}
## Backtesting
## Create GJR-std specification for comparison
gjr.s <- CreateSpec(variance.spec = list(model = "gjrGARCH"),
distribution.spec = list(distribution = "std"),
switch.spec = list(K = 1))
models <- list(gjr.s, ms2.gjr.s)
n.ots    <- 1000 # number of out-of-sample evaluation
n.its    <- 1500 # fit sample size
alpha    <- 0.05 # risk Level
k.update <- 100  # estimation frequency
## Initialization
VaR   <- matrix(NA, nrow = n.ots, ncol = length(models))
y.ots <- matrix(NA, nrow = n.ots, ncol = 1)
model.fit <- vector(mode = "list", length = length(models))
# iterate over out-of-sample time
for (i in 1:n.ots) {
cat("Backtest - Iteration: ", i, "\n")
y.its    <- SMI[i:(n.its + i - 1)] # in-sample data
y.ots[i] <- SMI[n.its + i]         # out-of-sample data
# iterate over models
for (j in 1:length(models)) {
# do we update the model estimation
if (k.update == 1 || i %% k.update == 1) {
cat("Model", j, "is reestimated\n")
model.fit[[j]] <- FitML(spec = models[[j]], data = y.its,
ctr = list(do.se = FALSE))
}
# calculate VaR 1-step ahead
VaR[i,j] <- Risk(model.fit[[j]]$spec, par = model.fit[[j]]$par,
data = y.its,
n.ahead = 1,
alpha   = alpha,
do.es   = FALSE,
do.its  = FALSE)$VaR
}
}
## Test the VaR
# install.packages("GAS")
library("GAS")
CC.pval <- DQ.pval <- vector("double", length(models))
for (j in 1:length(models)) {
test <- GAS::BacktestVaR(data  = y.ots,
VaR   = VaR[,j],
alpha = alpha)
CC.pval[j] <- test$LRcc[2]
DQ.pval[j] <- test$DQ$pvalue
}
names(CC.pval) <- names(DQ.pval) <- c("GJR-std", "MS2-GJR-std")
print(CC.pval)
print(DQ.pval)
sink()
############################################
################# FIGURES ##################
############################################
######################
##     FIGURE 1     ##
######################
pdf(file = "figure1.pdf", height = 13, width = 16, compress = TRUE)
par(mfrow = c(1, 1), mar = c(5,3,2,2) + 0.1)
plot(SMI, type = 'l', las = 1, lwd = 2, xlab = "Date (year)",
ylab = "", col = "black", cex.axis = 1.5, cex.lab = 1.5)
title("SMI log-returns (%)", cex.main = 1.5)
dev.off()
######################
##     FIGURE 2     ##
######################
pdf(file = "figure2.pdf", height = 13, width = 16, compress = TRUE)
op <- par(mfrow = c(2,1),
oma = c(1,1,0,0) + 0.0,
mar = c(2,2,2,2) + 0.0)
plot(as.vector(SMI), las = 1, type = 'p', pch = 20, col = 'black',
cex = 1.5, axes = FALSE, ann = FALSE)
par(new = TRUE)
ylabel <- expression(paste("Pr(", s[t], " = 2 | ", hat(psi), ", ", I[t], ")"))
plot(zoo::zoo(smoothed.prob, order.by = zoo::index(SMI)), lty = 1, plot.type = "single",
col = "red", las = 1, ylab = "", xlab = "Date", lwd = 3, cex.axis = 1.5, cex.lab = 1.5)
title(main = "Smoothed probabilities", cex.main = 1.5)
plot(zoo::zoo(vol, order.by = zoo::index(SMI)), lty = 1, plot.type = "single",
col = "black", las = 1, ylab = "", xlab = "Date", lwd = 3, cex.axis = 1.5, cex.lab = 1.5)
title(main = "Volatility (%)", cex.main = 1.5)
par(op)
dev.off()
######################
##     FIGURE 3     ##
######################
sel <- c("alpha1_1", "alpha2_1")
tmp <- draws[, sel]
par.mle <- fit.ml$par[sel]
par.bay <- apply(tmp, 2, mean)
xlim <- range(c(tmp[,1], par.mle[1]))
ylim <- range(c(tmp[,2], par.mle[2]))
pdf(file = "figure3.pdf", height = 13, width = 13, compress = TRUE)
par(mfrow = c(1, 1))
plot(tmp, pch = 20, las = 1, lwd = 2, cex = 2, xlim = xlim, ylim = ylim,
col = "lightsteelblue", cex.axis = 1.5, cex.lab = 1.5)
grid()
par(new = TRUE)
points(par.bay[1], par.bay[2], cex = 4, lwd = 2,
pch = 15, col = "blue", xlim = xlim, ylim = ylim)
points(par.mle[1], par.mle[2], cex = 4, lwd = 2,
pch = 17, col = "red", xlim = xlim, ylim = ylim)
dev.off()
######################
##     FIGURE 4     ##
######################
n <- length(ucvol.draws$ucvol_1)
pdf(file = "figure4.pdf", height = 13, width = 16, compress = TRUE)
op <- par(mar = c(2, 2, 2, 2),
mfrow = c(1, 2),
oma = c(2, 2, 0.2, 0.2))
hist(ucvol.draws$ucvol_1, nclass = round(10 * log(n)), prob = TRUE,
col = "lightsteelblue", las = 1, xlab = "Volatility (%)",
ylab = "", cex.lab = 1.5, cex.axis = 1.5, main = "")
title(main = "Regime 1", cex.main = 1.5)
lines(density(ucvol.draws$ucvol_1), col = "black", lwd = 2)
rug(ucvol.draws$ucvol_1); box()
points(ucvol.bay$ucvol_1, 0, pch = 15, col = "blue", lwd = 2, cex = 3)
points(ucvol.mle$ucvol_1, 0, pch = 17, col = "red", lwd = 2, cex = 3)
hist(ucvol.draws$ucvol_2, nclass = round(10 * log(n)), prob = TRUE,
col = "lightsteelblue", las = 1, xlab = "Volatility (%)",
ylab = "", cex.lab = 1.5, cex.axis = 1.5, main = "")
rug(ucvol.draws$ucvol_2); box()
points(ucvol.bay$ucvol_2, 0, pch = 15, col = "blue", lwd = 2, cex = 3)
points(ucvol.mle$ucvol_2, 0, pch = 17, col = "red", lwd = 2, cex = 3)
title(main = "Regime 2", cex.main = 1.5)
lines(density(ucvol.draws$ucvol_2), col = "black", lwd = 2)
par(op)
dev.off()
######################
##     FIGURE 5     ##
######################
pdf(file = "figure5.pdf", height = 13, width = 16, compress = TRUE)
#png(filename = "figure5.png", height = 13, width = 16, units = "in", res = 600)
xlim <- c(-4, -1.2)
ylim <- c(0, 0.1)
par(mfrow = c(1, 1))
matplot(x, t(pred.draws), xlim = xlim, ylim = ylim,
type = "l", col = "lightsteelblue",
xlab = "Return (%)", ylab = "Predictives",
lty = 1.5, las = 1, cex.axis = 1.5, cex.lab = 1.5)
title(main = "Left-tail forecast of SMI index return", cex.main = 1.5)
lines(x, pred.bay, xlim = xlim, ylim = ylim,
type = "l", lty = "solid", col = "blue", lwd = 3)
lines(x, pred.mle, xlim = xlim, ylim = ylim,
type = "l", pch = "o", lty = "dashed", col = "red", lwd = 3)
legend("topleft", c("MCMC draws", "Bayesian","ML"),
col = c("lightsteelblue", "blue", "red"), lwd = 3,
lty = c(1, 1, 2), bty = "n", cex = 2)
box()
dev.off()
######################
##     FIGURE 6     ##
######################
library("zoo")
time.index <- zoo::index(SMI)[(n.its + 1):(n.ots + n.its)]
y_ots <- zoo::zoo(y.ots, order.by = time.index)
VaR   <- zoo::zoo(VaR, order.by = time.index)
pdf(file = "figure6.pdf", height = 13, width = 16, compress = TRUE)
par(mfrow = c(1, 1))
plot(y_ots, type = 'p', las = 1, lwd = 1, xlab = "Date (year)",
ylab = "", col = "black", cex.axis = 1.5, cex.lab = 1.5, pch = 19)
lines(VaR[,1], type = 'l', col = "red", lwd = 3, lty = "dashed")
lines(VaR[,2], type = 'l', col = "blue", lwd = 3)
legend("topleft", legend = c("VaR 5% - GJR-std", "VaR 5% - MS2-GJR-std"),
col = c("red", "blue"), lwd = 3, cex = 1.5, lty = c("dashed", "solid"))
abline(h = 0)
title("Backtesing VaR at 5% risk level", cex.main = 1.5)
dev.off()
install.packages("devtools")
setwd("E:/Dropbox/Working Paper/GWP/GWP")
devtools::install()
install.packages("revdevcheck")
devtools::check()
devtools::check()
devtools::check()
setwd("E:/Dropbox/Working Paper/GWP/GWP")
devtools::install()
testthat::context("Test Normalized Frequencies")
# Load example data
data(corpus,  package = "GWP")
#' # Setup the lexicons
sentimentWord = sentometrics::list_lexicons$LM_en$x
shifterWord = sentometrics::list_valence_shifters$en[,c("x","y")]
frequencies <- computeFrequencies(corpus[1:100,], sentimentWord, shifterWord,clusterSize = 5)
test_value = c(0.00457,0.00887)
test_run = c(round(frequencies$NormalizedFrequency[1],5),round(frequencies$NormalizedFrequency[752],5))
testthat::expect_true(all(test_value == test_run))
all(test_value == test_run)
testthat::context("Fitting")
# Load example data
data("corpus",  package = "GWP")
data("vix",  package = "GWP")
#' # Setup the lexicons
sentimentWord = sentometrics::list_lexicons$LM_en$x
shifterWord = sentometrics::list_valence_shifters$en[,c("x","y")]
set.seed(1234)
frequencies <- computeFrequencies(corpus[1:1000,], sentimentWord, shifterWord,clusterSize = 5)
res = fitGWP(frequencies = frequencies, responseData = vix)
test_value = c(757.615, 0.014)
test_run = round(res$scores[1,2:3],3)
testthat::expect_true(all(test_value == test_run))
test_value
test_run
set.seed(1234)
frequencies <- computeFrequencies(corpus[1:1000,], sentimentWord, shifterWord,clusterSize = 5)
res = fitGWP(frequencies = frequencies, responseData = vix)
test_value = c(820.925, 0.014)
test_run = round(res$scores[1,2:3],3)
testthat::expect_true(all(test_value == test_run))
testthat::context("test pred")
# Load example data
data("corpus",  package = "GWP")
data("vix",  package = "GWP")
#' # Setup the lexicons
sentimentWord = sentometrics::list_lexicons$LM_en$x
shifterWord = sentometrics::list_valence_shifters$en[,c("x","y")]
set.seed(1234)
frequencies <- computeFrequencies(corpus[1:1000,], sentimentWord, shifterWord,clusterSize = 5)
res = fitGWP(frequencies = frequencies, responseData = vix)
newfrequencies <- computeFrequencies(corpus[1001:1100,], sentimentWord, shifterWord,clusterSize = 5)
pred = predictGWP(newfrequencies,model = res)
test_value = c(1.481)
test_run = round(pred[1,2],3)
test_run
devtools::check()
devtools::check()
setwd("E:/Dropbox/Working Paper/GWP/GWP/data")
setwd("E:/Dropbox/Working Paper/GWP/GWP/data")
tools::resaveRdaFiles(,compress = "bzip2")
setwd("E:/Dropbox/Working Paper/GWP/GWP/data")
tools::resaveRdaFiles(getwd(),compress = "bzip2")
setwd("E:/Dropbox/Working Paper/GWP/GWP")
devtools::check()
devtools::check()
devtools::build()
devtools::build()
devtools::check()
devtools::check()
devtools::build()
devtools::build()
devtools::build()
devtools::build()
devtools::build()
devtools::build()
devtools::build()
devtools::build()
library(devtools)
install_github("keblu/GWP")
